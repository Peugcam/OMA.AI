# üìö Guia de Uso - M√≥dulos Otimizados OMA v3.0

## üéØ Vis√£o Geral

Este guia explica como usar os novos m√≥dulos otimizados criados para reduzir custo e lat√™ncia do sistema OMA.

### M√≥dulos Criados

```
core/
‚îú‚îÄ‚îÄ __init__.py          # Exports principais
‚îú‚îÄ‚îÄ ai_client.py         # Cliente unificado LLM/SLM
‚îú‚îÄ‚îÄ router.py            # SmartRouter com cache
‚îú‚îÄ‚îÄ prompts.py           # Templates de prompts
‚îî‚îÄ‚îÄ validators.py        # Valida√ß√£o e parsing
```

---

## üöÄ Quick Start

### 1. Testar Sistema

```bash
# Inicie Ollama (para SLMs locais)
D:\OMA_Portable\start_ollama.bat

# Em outra janela, rode os testes
cd C:\Users\paulo\OneDrive\Desktop\OMA_REFACTORED
python test_optimized_supervisor.py
```

### 2. Importar M√≥dulos

```python
# Imports principais
from core import (
    AIClient,
    AIClientFactory,
    SmartRouter,
    PromptTemplates,
    ResponseValidator
)
```

---

## üìò M√≥dulo 1: AIClient

### O que √©?

Cliente abstrato para LLMs/SLMs (locais ou cloud). Elimina duplica√ß√£o de c√≥digo de chamada de API.

### Uso B√°sico

```python
from core import AIClient

# SLM Local (Phi3:mini via Ollama)
client = AIClient(model="phi3:mini", use_local=True)

response = client.chat(
    messages=[{"role": "user", "content": "Ol√°!"}],
    temperature=0.3,
    max_tokens=100
)
print(response)
```

### Uso Avan√ßado: JSON

```python
# Automaticamente instrui modelo a retornar JSON
response_dict = client.chat_json(
    messages=[{"role": "user", "content": "Liste 3 cores"}],
    temperature=0.5
)
# {"colors": ["vermelho", "azul", "verde"]}
```

### Factory Pattern

```python
from core import AIClientFactory

# Criar cliente baseado no .env
supervisor = AIClientFactory.create_for_agent("supervisor")
script = AIClientFactory.create_for_agent("script")

# Criar todos de uma vez
clients = AIClientFactory.create_all_agents()
# {"supervisor": <AIClient>, "script": <AIClient>, ...}
```

### Estat√≠sticas

```python
# Ap√≥s uso
client.print_stats()

# Sa√≠da:
# ==========================================
# üìä ESTAT√çSTICAS - Ollama (Local)
# ==========================================
# Modelo: phi3:mini
# Total de chamadas: 10
# Tempo m√©dio: 150ms
# Tokens totais: 5,000
# ==========================================
```

---

## üìò M√≥dulo 2: SmartRouter

### O que √©?

Router inteligente que usa SLM local para decis√µes de roteamento, com cache para evitar chamadas duplicadas.

### Uso B√°sico

```python
from core import SmartRouter

router = SmartRouter(enable_cache=True)

# Estado do v√≠deo
state = {
    "current_phase": 0,
    "script": None,
    "visual_plan": None,
    "audio_files": None,
    "video_path": None
}

# Decis√£o de roteamento
next_agent = router.route(state)
# "script_agent"
```

### Fluxo Completo

```python
# 1. In√≠cio
state1 = {"script": None, "visual_plan": None, ...}
router.route(state1)  # "script_agent"

# 2. Script conclu√≠do
state2 = {"script": {...}, "visual_plan": None, ...}
router.route(state2)  # "visual_agent" ou "audio_agent"

# 3. Script + Visual conclu√≠dos
state3 = {"script": {...}, "visual_plan": {...}, "audio_files": None, ...}
router.route(state3)  # "audio_agent"

# 4. Tudo pronto
state4 = {"script": {...}, "visual_plan": {...}, "audio_files": {...}, "video_path": None}
router.route(state4)  # "editor_agent"

# 5. V√≠deo finalizado
state5 = {..., "video_path": "./output.mp4"}
router.route(state5)  # "FINISH"
```

### Cache

```python
# Mesma decis√£o 2x = cache hit
router.route(state1)  # Chama SLM (200ms)
router.route(state1)  # Cache (0ms)

router.print_stats()
# Taxa de cache: 50%
# Economia: 1 chamada evitada
```

### Fallback

```python
# Se SLM falhar, usa regras determin√≠sticas
router = SmartRouter(enable_fallback=True)

# SLM offline/erro ‚Üí fallback autom√°tico
next_agent = router.route(state)  # Ainda funciona!
```

---

## üìò M√≥dulo 3: PromptTemplates

### O que √©?

Templates parametrizados para todos os agentes. Evita duplica√ß√£o de prompts e garante consist√™ncia.

### Routing

```python
from core import PromptTemplates

state = {"current_phase": 1, "script": {...}, ...}

# Prompt para decis√£o de roteamento
prompt = PromptTemplates.routing_decision(state)

# Sa√≠da:
# Fase: 1
# Script: ‚úì
# Visual: ‚úó
# Audio: ‚úó
# Video: ‚úó
#
# Pr√≥ximo agente:
```

### Script Generation

```python
prompt = PromptTemplates.script_generation(
    description="Propaganda cafeteria moderna",
    target_audience="Millennials urbanos",
    duration=30,
    style="Clean e minimalista",
    cta="Visite nossa loja"
)

# Prompt completo com estrutura JSON esperada
```

### Visual Keywords

```python
prompt = PromptTemplates.visual_keywords(
    scene_description="Barista preparando caf√©",
    mood="profissional",
    duration=5
)

# Retorna prompt para gerar keywords de busca
```

### Audio Plan

```python
prompt = PromptTemplates.audio_plan(
    narration_text="Cada x√≠cara √© feita com paix√£o...",
    duration=30,
    music_style="indie lo-fi",
    scenes=[...]
)
```

### System Prompts

```python
# Cada agente tem system prompt otimizado
system = PromptTemplates.script_system_prompt()
system = PromptTemplates.visual_system_prompt()
system = PromptTemplates.audio_system_prompt()
```

---

## üìò M√≥dulo 4: ResponseValidator

### O que √©?

Validadores para parsing e valida√ß√£o de respostas de IA.

### Parse JSON

```python
from core import ResponseValidator

# JSON v√°lido
result = ResponseValidator.parse_json('{"a": 1}')
# {"a": 1}

# JSON inv√°lido (com default)
result = ResponseValidator.parse_json('invalid', default={})
# {}
```

### Extrair JSON de Texto

```python
# Modelo adiciona texto extra
text = 'Aqui est√° o resultado: {"status": "ok"} e mais texto'

result = ResponseValidator.extract_first_json(text)
# {"status": "ok"}
```

### Validar Agente

```python
# Verificar se nome de agente √© v√°lido
ResponseValidator.validate_agent_name("script_agent")  # True
ResponseValidator.validate_agent_name("invalid")       # False
```

### Limpar Nome

```python
# Limpar resposta de roteamento
clean = ResponseValidator.clean_agent_name("  visual_agent\n")
# "visual_agent"

clean = ResponseValidator.clean_agent_name("O pr√≥ximo √©: audio_agent")
# "audio_agent"
```

### Validar Schema

```python
data = {"a": 1, "b": 2}

valid, missing = ResponseValidator.validate_json_schema(
    data,
    required_keys=["a", "b", "c"]
)
# (False, ["c"])
```

### Valida√ß√£o de VideoState

```python
from core import VideoStateValidator

# Validar script
script = {"script_id": "...", "scenes": [...], "duration_seconds": 30}

valid, error = VideoStateValidator.validate_script(script)
if not valid:
    print(f"Erro: {error}")
```

---

## üéØ Exemplo Completo: Uso Integrado

```python
from core import (
    AIClientFactory,
    SmartRouter,
    PromptTemplates,
    ResponseValidator
)

# 1. Criar clientes
clients = AIClientFactory.create_all_agents()
supervisor_client = clients["supervisor"]
script_client = clients["script"]

# 2. Criar router
router = SmartRouter(enable_cache=True)

# 3. Estado inicial
state = {
    "task_id": "video_001",
    "current_phase": 0,
    "script": None,
    "visual_plan": None,
    "audio_files": None,
    "video_path": None
}

# 4. Loop de execu√ß√£o
while True:
    # Decidir pr√≥ximo agente
    next_agent = router.route(state)

    if next_agent == "FINISH":
        break

    print(f"Executando: {next_agent}")

    # Exemplo: Script Agent
    if next_agent == "script_agent":
        # Criar prompt
        prompt = PromptTemplates.script_generation(
            description="Propaganda cafeteria",
            target_audience="Millennials",
            duration=30,
            style="Clean",
            cta="Visite"
        )

        # Chamar modelo
        response = script_client.chat_json(
            messages=[{"role": "user", "content": prompt}],
            temperature=0.8
        )

        # Validar
        valid, error = ResponseValidator.validate_json_schema(
            response,
            required_keys=["script_id", "scenes", "duration_seconds"]
        )

        if valid:
            state["script"] = response
            state["current_phase"] = 1
        else:
            print(f"Erro: {error}")
            break

    # ... outros agentes ...

# Estat√≠sticas
router.print_stats()
supervisor_client.print_stats()
script_client.print_stats()
```

---

## üìä Compara√ß√£o: Antes vs Depois

### ANTES (c√≥digo duplicado)

```python
# Em cada agente, repetir:
from openai import OpenAI

client = OpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=os.getenv("OPENROUTER_API_KEY")
)

response = client.chat.completions.create(
    model="qwen/qwen-2.5-7b-instruct",
    messages=[{"role": "user", "content": "..."}],
    temperature=0.7
)

result = response.choices[0].message.content

# Parse JSON manualmente
try:
    data = json.loads(result)
except:
    # Tratar erro...
```

**Problemas:**
- ‚ùå C√≥digo duplicado em 5 agentes
- ‚ùå Sem abstra√ß√£o
- ‚ùå Dif√≠cil trocar modelos
- ‚ùå Sem estat√≠sticas
- ‚ùå Sem cache

### DEPOIS (com m√≥dulos otimizados)

```python
from core import AIClient, ResponseValidator

client = AIClient(model="phi3:mini", use_local=True)

data = client.chat_json(
    messages=[{"role": "user", "content": "..."}],
    temperature=0.7
)

# JSON j√° parseado, validado, com stats!
client.print_stats()
```

**Benef√≠cios:**
- ‚úÖ Zero duplica√ß√£o
- ‚úÖ Abstra√ß√£o limpa
- ‚úÖ Trocar modelo = mudar 1 linha
- ‚úÖ Estat√≠sticas autom√°ticas
- ‚úÖ JSON autom√°tico

---

## üéØ Pr√≥ximos Passos

1. ‚úÖ **Teste os m√≥dulos**
   ```bash
   python test_optimized_supervisor.py
   ```

2. ‚úÖ **Integre no Supervisor**
   - Ver: `agents/supervisor_agent.py`
   - Substituir c√≥digo antigo por novos m√≥dulos

3. ‚úÖ **Adapte outros agentes**
   - Script Agent ‚Üí usar `AIClient` + `PromptTemplates`
   - Visual Agent ‚Üí usar `AIClient` + `ResponseValidator`
   - Audio Agent ‚Üí usar `AIClient` + `PromptTemplates`
   - Editor Agent ‚Üí usar `AIClient` + `PromptTemplates`

4. ‚úÖ **Monitore resultados**
   - Comparar tempo de execu√ß√£o
   - Comparar custos
   - Ajustar temperaturas/prompts

---

## üêõ Troubleshooting

### Erro: "Module 'core' not found"

```bash
# Certifique-se de estar na pasta raiz do projeto
cd C:\Users\paulo\OneDrive\Desktop\OMA_REFACTORED

# Ou adicione ao PYTHONPATH
export PYTHONPATH="${PYTHONPATH}:/caminho/para/OMA_REFACTORED"
```

### Erro: "Ollama not found"

```bash
# Inicie Ollama
D:\OMA_Portable\start_ollama.bat

# Verifique se est√° rodando
curl http://localhost:11434/api/version
```

### Erro: "OPENROUTER_API_KEY not set"

```bash
# Verifique .env
cat .env | grep OPENROUTER_API_KEY

# Deve ter:
# OPENROUTER_API_KEY=sk-or-v1-sua-chave-aqui
```

### Router sempre usa fallback

- Verifique se Ollama est√° rodando
- Verifique se modelo phi3:mini est√° instalado: `ollama list`
- Teste manualmente: `ollama run phi3:mini "Ol√°"`

---

## üìö Documenta√ß√£o Adicional

- **Estrat√©gia Completa**: `ESTRATEGIA_HIBRIDA_OTIMIZADA.md`
- **Altern√¢ncia de Modelos**: `COMO_ALTERNAR_MODELOS.md`
- **Configura√ß√£o**: `.env` (coment√°rios inline)

---

**Criado em:** 18/11/2025
**Vers√£o:** 3.0.0
**Status:** ‚úÖ Pronto para uso!
